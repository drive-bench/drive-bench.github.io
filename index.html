<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives">
  <meta name="keywords" content="Autonomous Driving, Vision-Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DriveBench</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>


  <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <link rel="icon" href="./static/icons/robustness.png" type="image/x-icon">


  <style>
    .fixed-width-section {
      max-width: 1000px; /* Set a fixed width */
      margin: 0 auto; /* Center the section horizontally */
      padding: 0 15px; /* Add some padding to prevent overflow on small screens */
    }

    @media (max-width: 768px) {
    .fixed-width-section {
      max-width: 90%; /* Allow up to 90% of the screen width on phones */
      padding: 0 10px; /* Reduce padding on smaller screens */
    }}

    /* Back to Top Button */
    #backToTopBtn {
      position: fixed;
      bottom: 20px;
      right: 50px;
      z-index: 999;
      background-color: rgb(66, 133, 244);
      color: white;
      border: none;
      border-radius: 50%; /* Circular button */
      padding: 12px 16px;
      font-size: 20px;
      cursor: pointer;
      box-shadow: 0px 4px 8px rgba(0,0,0,0.2);
      transition: opacity 0.3s;
      display: none; /* Hidden by default */
    }
    
    #backToTopBtn:hover {
      background-color: rgb(192, 0, 0);
    }
    
    @media (max-width: 768px) {
      #backToTopBtn {
        font-size: 18px;
        padding: 10px 14px;
      }
    }
  </style>
</head>


<body>


  <button onclick="scrollToTop()" id="backToTopBtn" title="Go to top">↑</button>

  <script>
    // Show the button when scrolled down 20px
    window.onscroll = function() {
      scrollFunction();
    };
  
    function scrollFunction() {
      const button = document.getElementById("backToTopBtn");
      if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
        button.style.display = "block";
      } else {
        button.style.display = "none";
      }
    }
  
    // Smooth scroll to top
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
  </script>



<nav class="navbar" role="navigation" aria-label="main navigation">
  <!-- <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/ldkong1205/Robo3D" target="_blank">
            ICCV 2023 | Robo3D 
          </a>
          <a class="navbar-item" href="https://github.com/ldkong1205/RoboDepth" target="_blank">
            NeurIPS 2023 | RoboDepth
          </a>
          <a class="navbar-item" href="https://robodrive-24.github.io/" target="_blank">
            ICRA 2024 | RoboDrive
          </a>
          <a class="navbar-item" href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">
            TPAMI 2024 | RoboBEV
          </a>
          <a class="navbar-item" href="https://github.com/OpenDriveLab/DriveLM" target="_blank">
            ECCV 2024 | DriveLM
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title">
            <img src="./static/icons/human.png" style="height: 38px; vertical-align: top;">Are VLMs Ready for Autonomous Driving?<br/>An Empirical Study from the Reliability, Data, and Metric Perspectives
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://daniel-xsy.github.io/" target="_blank">
                <b>Shaoyuan Xie</b></a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://ldkong.com/" target="_blank">
                <b>Lingdong Kong</b></a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://github.com/dongyh20" target="_blank">
                <b>Yuhao Dong</b></a><sup>2,4</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://github.com/ChonghaoSima" target="_blank">
                <b>Chonghao Sima</b></a><sup>2,5</sup>
            </span>
            <br/>
            <span class="author-block">
              <a href="http://zhangwenwei.cn/" target="_blank">
                <b>Wenwei Zhang</b></a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://ics.uci.edu/~alfchen/" target="_blank">
                <b>Qi Alfred Chen</b></a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://liuziwei7.github.io/" target="_blank">
                <b>Ziwei Liu</b></a><sup>4</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ" target="_blank">
                <b>Liang Pan</b></a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>University of California, Irvine&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <sup>2</sup>Shanghai AI Laboratory&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <sup>3</sup>National University of Singapore
            </span>
            <span class="author-block">
              <sup>4</sup>S-Lab, Nanyang Technological University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <sup>5</sup>The University of Hong Kong
            </span>
          </div>

          <!-- <div class="is-size-5 publication-authors" style="font-size: 0.5rem;">
            <span class="author-block">
              <sup>&#8225</sup>Project Lead&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <sup>&#167;</sup>Corresponding Author
            </span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2501.04003" target="_blank"
                   class="external-link button is-dark"
                   style="background-color: rgb(66, 133, 244); color: white; border-color: rgb(66, 133, 244);">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span><b>Paper</b></span>
                </a>
              </span>

              &nbsp;
              <span class="link-block">
                <a href="https://arxiv.org/abs/2501.04003" target="_blank"
                   class="external-link button is-dark"
                   style="background-color: rgb(192, 0, 0); color: white; border-color: rgb(192, 0, 0);">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span><b>arXiv</b></span>
                </a>
              </span>
              &nbsp;
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/drive-bench/toolkit" target="_blank"
                   class="external-link button is-dark"
                   style="background-color: rgb(66, 133, 244); color: white; border-color: rgb(66, 133, 244);">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span><b>Toolkit</b></span>
                  </a>
              </span>
              &nbsp;
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/drive-bench/arena" target="_blank"
                   class="external-link button is-dark"
                   style="background-color: rgb(192, 0, 0); color: white; border-color: rgb(192, 0, 0);">
                  <span class="icon"><i class="fa fa-database" aria-hidden="true"></i></span>
                  <span><b>Dataset</b></span>
                  </a>
              </span>
              &nbsp;
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-dark"
                   style="background-color: rgb(66, 133, 244); color: white; border-color: rgb(66, 133, 244);">
                  <span class="icon"><i class="fa fa-balance-scale" aria-hidden="true"></i></span>
                  <span><b>Leaderboard</b></span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in Vision-Language Models (VLMs) have sparked interest in their use for autonomous driving, particularly in generating interpretable driving decisions through natural language. 
            However, the assumption that VLMs inherently provide visually grounded, reliable, and interpretable explanations for driving remains largely unexamined. 
            To address this gap, we introduce <strong><span style="font-family: 'Nunito', sans-serif; color: rgb(66, 133, 244);">Drive</span><span style="font-family: 'Nunito', sans-serif; color: rgb(192, 0, 0);">Bench</span></strong>, a benchmark dataset designed to evaluate VLM reliability across <b>17 settings</b> (clean, corrupted, and text-only inputs), encompassing <b>19,200 frames</b>, <b>20,498 question-answer pairs</b>, <b>three question types</b>, <b>four mainstream driving tasks</b>, and <b>a total of 12 popular VLMs</b>. 
            Our findings reveal that VLMs often generate plausible responses derived from general knowledge or textual cues rather than true visual grounding, especially under degraded or missing visual inputs. 
            This behavior, concealed by dataset imbalances and insufficient evaluation metrics, poses significant risks in safety-critical scenarios like autonomous driving. 
            We further observe that VLMs struggle with multi-modal reasoning and display heightened sensitivity to input corruptions, leading to inconsistencies in performance. 
            To address these challenges, we propose refined evaluation metrics that prioritize robust visual grounding and multi-modal understanding. 
            Additionally, we highlight the potential of leveraging VLMs’ awareness of corruptions to enhance their reliability, offering a roadmap for developing more trustworthy and interpretable decision-making systems in real-world autonomous driving contexts. 
            The benchmark toolkit is publicly accessible.
          </p>
        </div>
      </div>
    </div><hr>
  </div>
</section>




<section class="section" style="margin-top: -10px;">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths fixed-width-section">
      <h2 class="title is-3">
        <span class="icon"><i class="fas fa-bus"></i></span>&thinsp;&thinsp;<span style="color: rgb(66, 133, 244);">Drive</span><span style="color: rgb(192, 0, 0);">Bench</span>: Driving with VLMs
      </h2>
      <div class="pipeline" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
        <img src="static/figures/bench.png" style="width:100%"
            class="pipeline image" alt="benchmark"/>
        <br/>
        <p>
          <strong>Overview of key features and configurations in <span style="font-family: 'Nunito', sans-serif; color: rgb(66, 133, 244);">Drive</span><span style="font-family: 'Nunito', sans-serif; color: rgb(192, 0, 0);">Bench</span></strong>. 
          Our benchmark evaluates the reliability and visual grounding of VLMs in autonomous driving across <b>four mainstream driving tasks</b> - perception, prediction, planning, and explanation - under a diverse spectrum of <b>17 settings</b> (clean, corrupted, and text-only inputs). 
          It includes <b>19,200 frames</b> and <b>20,498 QA pairs</b> spanning <b>three question types</b>: multiple-choice, open-ended, and visual grounding. 
          By addressing diverse tasks and conditions, we aim to reveal VLM limitations and promote reliable, interpretable autonomous driving.
        </p>
      </div><hr>
    </div>
  </div>
</section>



<section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/teaser.png" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 40px;">
            <h2 class="title is-3">
              <span class="icon"><i class="fa fa-question-circle"></i></span>&thinsp; Are Existing VLMs Ready for Autonomous Driving?
            </h2>
            <p>
              We investigate this question through the lenses of <b>reliability</b>, <b>data quality</b>, and <b>evaluation metrics</b>. 
              Our findings reveal that current VLMs often fabricate convincing answers to driving-related questions, even in the absence of visual information. 
              These fabricated responses can bypass existing evaluation metrics, including GPT scores, due to issues such as dataset imbalance, insufficient contextual data, and flawed evaluation protocols. 
              These observations challenge the widely held assumption that VLMs inherently provide more reliable, visually grounded, and interpretable responses than task-specific models in driving scenarios.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>


  <br/>


  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">
        <span class="icon"><i class="fas fa-child"></i></span>&thinsp;Interactive Demo
      </h2>
      <div class="columns">
        <!-- Sidebar (button groups) -->
        <div class="column is-one-quarter">
          <div style="margin-bottom: 1rem;">
            <p class="menu-label">Case</p>
            <div id="caseButtons" style="display: flex; gap: 0.5rem;"></div>
          </div>
  
          <div style="margin-bottom: 1rem;">
            <p class="menu-label">Model</p>
            <div id="modelButtons" style="display: flex; flex-wrap: wrap; gap: 0.5rem;"></div>
          </div>
  
          <div style="margin-bottom: 1rem;">
            <p class="menu-label">Corruption</p>
            <div id="corruptionButtons" style="display: flex; flex-wrap: wrap; gap: 0.5rem;"></div>
          </div>
  
          <div style="margin-bottom: 1rem;">
            <p class="menu-label">Prompt</p>
            <div id="promptButtons" style="display: flex; flex-wrap: wrap; gap: 0.5rem;"></div>
          </div>
        </div>
  
        <!-- Content Area -->
        <div class="column">
          <!-- Images Container -->
          <div id="imageContainer" class="columns is-multiline is-centered"></div>
          <hr>
  
          <!-- Rows for icons and text -->
          <div class="columns">
            <div class="column is-one-quarter">
              <img src="./static/images/icon1.png" alt="Icon 1" loading="lazy" style="width: 30%; max-width: 100px; float: right;">
            </div>
            <div class="column" id="questionContainer"
                 style="max-height: 150px; overflow-y: auto; padding: 10px; border: 1px solid #ccc; margin: 10px; box-sizing: border-box;">
              <!-- Question text goes here -->
            </div>
          </div>
  
          <div class="columns">
            <div class="column is-one-quarter">
              <img src="./static/images/icon2.png" alt="Icon 2" loading="lazy" style="width: 30%; max-width: 100px; float: right;">
            </div>
            <div class="column" id="answerContainer"
                 style="max-height: 150px; overflow-y: auto; padding: 10px; border: 1px solid #ccc; margin: 10px; box-sizing: border-box;">
              <!-- Model’s answer goes here -->
            </div>
          </div>
  
          <div class="columns">
            <div class="column is-one-quarter">
              <img src="./static/images/icon3.png" alt="Icon 3" loading="lazy" style="width: 30%; max-width: 100px; float: right;">
            </div>
            <div class="column" id="gtContainer"
                 style="max-height: 150px; overflow-y: auto; padding: 10px; border: 1px solid #ccc; margin: 10px; box-sizing: border-box;">
              <!-- Ground-truth answer goes here -->
            </div>
          </div>
  
          <div class="columns">
            <div class="column is-one-quarter">
              <img src="./static/images/icon4.png" alt="Icon 4" loading="lazy" style="width: 30%; max-width: 100px; float: right;">
            </div>
            <div class="column" id="evaluatorContainer"
                 style="max-height: 150px; overflow-y: auto; padding: 10px; border: 1px solid #ccc; margin: 10px; box-sizing: border-box;">
              <!-- Evaluator text goes here -->
            </div>
          </div>
        </div>
      </div><hr>
    </div>
  </section>



  <br/>



  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths fixed-width-section">
      <h2 class="title is-3">
        Benchmark Comparison
      </h2>
          <div class="table-container">
            <table class="table is-bordered is-striped is-hoverable">
              <thead>
                <tr>
                  <th rowspan="2">Benchmark</th>
                  <th rowspan="2"><img src="static/icons/perception.png" loading="lazy" style="width: 40px; height: 40px; vertical-align: top;"><span>Perception</span></th>
                  <th rowspan="2"><img src="static/icons/prediction.png" loading="lazy" style="width: 40px; height: 40px; vertical-align: top;"><span>Prediction</span></th>
                  <th rowspan="2"><img src="static/icons/behavior.png" loading="lazy" style="width: 40px; height: 40px; vertical-align: top;"><span>Behavior</span></th>
                  <th rowspan="2"><img src="static/icons/planning.png" loading="lazy" style="width: 40px; height: 40px; vertical-align: top;"><span>Planning</span></th>
                  <th rowspan="2"><img src="static/icons/robustness.png" loading="lazy" style="width: 40px; height: 40px; vertical-align: top;"><span>Robustness</span></th>
                  <th>Frames</th>
                  <th>QA</th>
                  <th rowspan="2">Logic</th>
                  <th rowspan="2">Evaluation Metrics</th>
                </tr>
                <tr>
                  <th>(Test)</th>
                  <th>(Test)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
                </tr>
                <tr>
                  <td>BDD-X</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>-</td>
                  <td>-</td>
                  <td>None</td>
                  <td>Language</td>
                </tr>
                <tr>
                  <td>BDD-OIA</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>-</td>
                  <td>-</td>
                  <td>None</td>
                  <td>F1 Score</td>
                </tr>
                <tr>
                  <td>nuScenes-QA</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>36,114</td>
                  <td>83,337</td>
                  <td>None</td>
                  <td>Acc</td>
                </tr>
                <tr>
                  <td>Talk2Car</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>~1.8k</td>
                  <td>2,447</td>
                  <td>None</td>
                  <td>-</td>
                </tr>
                <tr>
                  <td>nuPrompt</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>~36k</td>
                  <td>~6k</td>
                  <td>None</td>
                  <td>AMOTA</td>
                </tr>
                <tr>
                  <td>DRAMA</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>-</td>
                  <td>~14k</td>
                  <td>Chain</td>
                  <td>Language</td>
                </tr>
                <tr>
                  <td>Rank2Tel</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>-</td>
                  <td>-</td>
                  <td>Chain</td>
                  <td>Acc, Language</td>
                </tr>
                <tr>
                  <td>DirveMLLM</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>880</td>
                  <td>-</td>
                  <td>None</td>
                  <td>Acc</td>
                </tr>
                <tr>
                  <td>DriveVLM</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>-</td>
                  <td>-</td>
                  <td>None</td>
                  <td>GPT<sub>ctx</sub></td>
                </tr>
                <tr>
                  <td>DriveLM</td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(192, 0, 0);">✘</span></td>
                  <td>4,794</td>
                  <td>15,480</td>
                  <td>Graph</td>
                  <td>Language, GPT</td>
                </tr>
                <tr>
                  <td><strong><span style="font-family: 'Nunito', sans-serif; color: rgb(66, 133, 244);">Drive</span><span style="font-family: 'Nunito', sans-serif; color: rgb(192, 0, 0);">Bench</span> (Ours)</strong></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><span style="color: rgb(0, 176, 80);">✔</span></td>
                  <td><b>19,200</b></td>
                  <td><b>20,498</b></td>
                  <td><b>Graph</b></td>
                  <td><b>Acc, Language, GPT, GPT<sub>ctx</sub></b></td>
                </tr>
              </tbody>     
            </table>
          </div><hr>
    </div>
  </div>

  

  <br/>



  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/cloud.png" loading="lazy" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 40px;">
            <h2 class="title is-3">
              Unique Data Collection
            </h2>
            <p>
              We analyze existing “Driving with Language” benchmarks and identify their issues, particularly dataset imbalance inherited from sources like nuScenes, BDD, and Waymo Open. 
              Our benchmark addresses these issues by curating a balanced dataset with diverse driving tasks, corruption types, and text-only inputs, enabling systematic evaluation of VLMs under real-world autonomous driving conditions. 
              This ensuress a reliable testbed for assessing VLMs in safety-critical scenarios.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>


  <br/>


<section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-right: 40px;">
            <h2 class="title is-3">
              Challenging Cases in Existing Dataset
            </h2>
            <p>
              (a): The black sedan is turning left, indicated by the turn lights. 
              (b): The black sedan is turning right. GPT4-o predicts <b>Going Ahead</b> for these two cases. 
            </p>
            <p>
              (c) and (d) are both <b>Turning Right</b>, but GPT4-o fails to locate the objects based on center pixel positions due to the existence of overlapping or occlusion.
            </p>
          </div>
        </div>
        <!-- Right Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/dataset_cases.jpg" loading="lazy" style="max-width: 100%; height: auto;" />
        </div>
      </div><hr>
    </div>
  </section>


  <br/>


  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/spatial_distribution.png" loading="lazy" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 40px;">
            <h2 class="title is-3">
              Spatial Distribution
            </h2>
            <p>
              We study the spatial distribution of predictions generated by Qwen2-VL (7B), under the <b>text-only prompts</b>. 
              We find that the model can potentially “guess” the MCQ answers without visual information by leveraging plain text cues,
              e.g., camera and coordinate positions mentioned in the questions, resulting in the hallucination issue.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>


  <br/><br/><br/>




<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">
      <span class="icon"><i class="fa fa-subway"></i></span>&thinsp; Benchmark Study
    </h2>
        <div class="table-container">
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th>Model</th>
                <th>Size</th>
                <th>Type</th>
                <th><img src="static/icons/perception.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Perception</span> (<span style="color: rgb(0, 176, 80);">Clean</span>)</th>
                <th><img src="static/icons/perception.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Perception</span> (<span style="color: rgb(192, 0, 0);">Corr.</span>)</th>
                <th><img src="static/icons/perception.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Perception</span> (<span style="color: rgb(66, 133, 244);">T.O.</span>)</th>
                <th><img src="static/icons/prediction.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Prediction</span> (<span style="color: rgb(0, 176, 80);">Clean</span>)</th>
                <th><img src="static/icons/prediction.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Prediction</span> (<span style="color: rgb(192, 0, 0);">Corr.</span>)</th>
                <th><img src="static/icons/prediction.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Prediction</span> (<span style="color: rgb(66, 133, 244);">T.O.</span>)</th>
                <th><img src="static/icons/planning.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Planning</span> (<span style="color: rgb(0, 176, 80);">Clean</span>)</th>
                <th><img src="static/icons/planning.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Planning</span> (<span style="color: rgb(192, 0, 0);">Corr.</span>)</th>
                <th><img src="static/icons/planning.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Planning</span> (<span style="color: rgb(66, 133, 244);">T.O.</span>)</th>
                <th><img src="static/icons/behavior.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Behavior</span> (<span style="color: rgb(0, 176, 80);">Clean</span>)</th>
                <th><img src="static/icons/behavior.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Behavior</span> (<span style="color: rgb(192, 0, 0);">Corr.</span>)</th>
                <th><img src="static/icons/behavior.png" loading="lazy" style="width: 37px; height: 37px; vertical-align: top;"><span>Behavior</span> (<span style="color: rgb(66, 133, 244);">T.O.</span>)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><span style="color: rgb(0, 176, 80);"><b>Human</b></span></td>
                <td>-</td>
                <td>-</td>
                <td><span style="color: rgb(0, 176, 80);">47.67</span></td>
                <td><span style="color: rgb(0, 176, 80);">38.32</span></td>
                <td>-</td>
                <td>-</td>
                <td>-</td>
                <td>-</td>
                <td>-</td>
                <td>-</td>
                <td>-</td>
                <td><span style="color: rgb(0, 176, 80);">69.51</span></td>
                <td><span style="color: rgb(0, 176, 80);">54.09</span></td>
                <td>-</td>
              </tr>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>GPT-4o</a></td>
                <td>-</td>
                <td>Commercial</td>
                <td>35.37</td>
                <td>35.25</td>
                <td>36.48</td>
                <td>51.30</td>
                <td>49.94</td>
                <td>49.05</td>
                <td>75.75</td>
                <td>75.36</td>
                <td>73.21</td>
                <td>45.40</td>
                <td>44.33</td>
                <td>50.03</td>
              </tr>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>LLaVA-1.5</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>23.22</td>
                <td>22.95</td>
                <td>22.31</td>
                <td>22.02</td>
                <td>17.54</td>
                <td>14.64</td>
                <td>29.15</td>
                <td>31.51</td>
                <td>32.45</td>
                <td>13.60</td>
                <td>13.62</td>
                <td>14.91</td>
              </tr>
              <tr>
                <td><a>LLaVA-1.5</a></td>
                <td>13B</td>
                <td>Open</td>
                <td>23.35</td>
                <td>23.37</td>
                <td>22.37</td>
                <td>36.98</td>
                <td>37.78</td>
                <td>23.98</td>
                <td>34.26</td>
                <td>34.99</td>
                <td>38.85</td>
                <td>32.99</td>
                <td>32.43</td>
                <td>32.79</td>
              </tr>
              <tr>
                <td><a>LLaVA-NeXT</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>24.15</td>
                <td>19.62</td>
                <td>13.86</td>
                <td>35.07</td>
                <td>35.89</td>
                <td>28.36</td>
                <td>45.27</td>
                <td>44.36</td>
                <td>27.58</td>
                <td>48.16</td>
                <td>39.44</td>
                <td>11.92</td>
              </tr>
              <tr>
                <td><a>InternVL2</a></td>
                <td>8B</td>
                <td>Open</td>
                <td>32.36</td>
                <td>32.68</td>
                <td>33.60</td>
                <td>45.52</td>
                <td>37.93</td>
                <td>48.89</td>
                <td>53.27</td>
                <td>55.25</td>
                <td>34.56</td>
                <td>54.58</td>
                <td>40.78</td>
                <td>20.14</td>
              </tr>
              <tr>
                <td><a>Phi-3</a></td>
                <td>4.2B</td>
                <td>Open</td>
                <td>22.88</td>
                <td>23.93</td>
                <td>28.26</td>
                <td>40.11</td>
                <td>37.27</td>
                <td>22.61</td>
                <td>60.03</td>
                <td>61.31</td>
                <td>46.88</td>
                <td>45.20</td>
                <td>44.57</td>
                <td>28.22</td>
              </tr>
              <tr>
                <td><a>Phi-3.5</a></td>
                <td>4.2B</td>
                <td>Open</td>
                <td>27.52</td>
                <td>27.51</td>
                <td>28.26</td>
                <td>45.13</td>
                <td>38.21</td>
                <td>4.92</td>
                <td>31.91</td>
                <td>28.36</td>
                <td>46.30</td>
                <td>37.89</td>
                <td>49.13</td>
                <td>39.16</td>
              </tr>
              <tr>
                <td><a>Oryx</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>17.02</td>
                <td>15.97</td>
                <td>18.47</td>
                <td>48.13</td>
                <td>46.63</td>
                <td>12.77</td>
                <td>53.57</td>
                <td>55.76</td>
                <td>48.26</td>
                <td>33.92</td>
                <td>33.81</td>
                <td>23.94</td>
              </tr>
              <tr>
                <td><a>Qwen2-VL</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>28.99</td>
                <td>27.85</td>
                <td>35.16</td>
                <td>37.89</td>
                <td>39.55</td>
                <td>37.77</td>
                <td>57.04</td>
                <td>54.78</td>
                <td>41.66</td>
                <td>49.07</td>
                <td>47.68</td>
                <td>54.48</td>
              </tr>
              <tr>
                <td><a>Qwen2-VL</a></td>
                <td>72B</td>
                <td>Open</td>
                <td>30.13</td>
                <td>26.92</td>
                <td>17.70</td>
                <td>49.35</td>
                <td>43.49</td>
                <td>5.57</td>
                <td>61.30</td>
                <td>63.07</td>
                <td>53.35</td>
                <td>51.26</td>
                <td>49.78</td>
                <td>39.46</td>
              </tr>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>DriveLM</a></td>
                <td>7B</td>
                <td>Specialist</td>
                <td>16.85</td>
                <td>16.00</td>
                <td>8.75</td>
                <td>44.33</td>
                <td>39.71</td>
                <td>4.70</td>
                <td>68.71</td>
                <td>67.60</td>
                <td>65.24</td>
                <td>42.78</td>
                <td>40.37</td>
                <td>27.83</td>
              </tr>
              <tr>
                <td><a>Dolphins</a></td>
                <td>7B</td>
                <td>Specialist</td>
                <td>9.59</td>
                <td>10.84</td>
                <td>11.01</td>
                <td>32.66</td>
                <td>29.88</td>
                <td>39.98</td>
                <td>52.91</td>
                <td>53.77</td>
                <td>60.98</td>
                <td>8.81</td>
                <td>8.25</td>
                <td>11.92</td>
              </tr>
            </tbody>
          </table>
          <span>
            <b>Table.</b> <strong>Evaluations of VLMs across different driving tasks</strong> (perception, prediction, planning, and behavior). <span style="color: rgb(0, 176, 80);">Clean</span> represents clean image inputs. <span style="color: rgb(192, 0, 0);">Corr.</span> represents corruption image inputs, averaged across fifteen corruptions. <span style="color: rgb(66, 133, 244);">T.O.</span> represents text-only evaluation. For humans, we only evaluate MCQ questions in perception and behavior tasks. The evaluations are based on GPT scores, where we tailored detailed rubrics for each task and question type.
          </span>
        </div><hr>
  </div>
</div>



<br/><br/>




<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">
      <span class="icon"><i class="fa fa-cogs"></i></span>&thinsp;&thinsp; Robustness Analysis
    </h2>
        <div class="table-container">
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th rowspan="2">Model</th>
                <th rowspan="2">Size</th>
                <th rowspan="2">Type</th>
                <th colspan="3"><img src="static/icons/weather.png" loading="lazy" style="width: 45px; height: 45px; vertical-align: top;"><span><br/></span>Weather</th>
                <th colspan="3"><img src="static/icons/external.png" loading="lazy" style="width: 45px; height: 45px; vertical-align: top;"><span><br/>External</th>
                <th colspan="3"><img src="static/icons/sensor.png" loading="lazy" style="width: 45px; height: 45px; vertical-align: top;"><span><br/>Sensor</th>
                <th colspan="3"><img src="static/icons/motion.png" loading="lazy" style="width: 45px; height: 45px; vertical-align: top;"><span><br/>Motion</th>
                <th colspan="3"><img src="static/icons/transmission.png" loading="lazy" style="width: 45px; height: 45px; vertical-align: top;"><span><br/>Transmission</th>
              </tr>
              <tr>
                <th><span style="color: rgb(66, 133, 244);">MCQ</span></th>
                <th><span style="color: rgb(192, 0, 0);">VQA</span></th>
                <th><span style="color: rgb(0, 176, 80);">CAP</span></th>
                <th><span style="color: rgb(66, 133, 244);">MCQ</span></th>
                <th><span style="color: rgb(192, 0, 0);">VQA</span></th>
                <th><span style="color: rgb(0, 176, 80);">CAP</span></th>
                <th><span style="color: rgb(66, 133, 244);">MCQ</span></th>
                <th><span style="color: rgb(192, 0, 0);">VQA</span></th>
                <th><span style="color: rgb(0, 176, 80);">CAP</span></th>
                <th><span style="color: rgb(66, 133, 244);">MCQ</span></th>
                <th><span style="color: rgb(192, 0, 0);">VQA</span></th>
                <th><span style="color: rgb(0, 176, 80);">CAP</span></th>
                <th><span style="color: rgb(66, 133, 244);">MCQ</span></th>
                <th><span style="color: rgb(192, 0, 0);">VQA</span></th>
                <th><span style="color: rgb(0, 176, 80);">CAP</span></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>GPT-4o</a></td>
                <td>-</td>
                <td>Commercial</td>
                <td>57.20</td>
                <td>57.28</td>
                <td>54.90</td>
                <td>29.25</td>
                <td>56.60</td>
                <td>61.98</td>
                <td>44.25</td>
                <td>54.95</td>
                <td>56.53</td>
                <td>34.25</td>
                <td>59.20</td>
                <td>56.25</td>
                <td>36.83</td>
                <td>53.95</td>
                <td>57.57</td>
              </tr>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>LLaVA-1.5</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>69.70</td>
                <td>35.49</td>
                <td>35.91</td>
                <td>26.50</td>
                <td>29.17</td>
                <td>34.95</td>
                <td>18.83</td>
                <td>30.64</td>
                <td>33.15</td>
                <td>71.25</td>
                <td>33.43</td>
                <td>35.18</td>
                <td>10.17</td>
                <td>27.28</td>
                <td>34.38</td>
              </tr>
              <tr>
                <td><a>LLaVA-1.5</a></td>
                <td>13B</td>
                <td>Open</td>
                <td>61.60</td>
                <td>39.76</td>
                <td>37.76</td>
                <td>15.50</td>
                <td>34.55</td>
                <td>37.83</td>
                <td>24.08</td>
                <td>35.48</td>
                <td>36.08</td>
                <td>79.75</td>
                <td>36.46</td>
                <td>36.42</td>
                <td>15.50</td>
                <td>32.53</td>
                <td>34.33</td>
              </tr>
              <tr>
                <td><a>LLaVA-NeXT</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>69.70</td>
                <td>36.96</td>
                <td>48.52</td>
                <td>48.50</td>
                <td>30.32</td>
                <td>57.18</td>
                <td>21.83</td>
                <td>30.40</td>
                <td>44.37</td>
                <td>66.00</td>
                <td>34.20</td>
                <td>50.44</td>
                <td>11.83</td>
                <td>29.43</td>
                <td>53.50</td>
              </tr>
              <tr>
                <td><a>InternVL2</a></td>
                <td>8B</td>
                <td>Open</td>
                <td>59.90</td>
                <td>48.72</td>
                <td>48.60</td>
                <td>50.75</td>
                <td>47.74</td>
                <td>57.82</td>
                <td>29.92</td>
                <td>45.06</td>
                <td>51.14</td>
                <td>68.25</td>
                <td>49.51</td>
                <td>49.67</td>
                <td>30.00</td>
                <td>43.42</td>
                <td>54.24</td>
              </tr>
              <tr>
                <td><a>Phi-3</a></td>
                <td>4.2B</td>
                <td>Open</td>
                <td>40.00</td>
                <td>40.59</td>
                <td>45.61</td>
                <td>25.00</td>
                <td>31.44</td>
                <td>45.99</td>
                <td>16.83</td>
                <td>35.58</td>
                <td>43.71</td>
                <td>31.25</td>
                <td>42.92</td>
                <td>48.43</td>
                <td>27.67</td>
                <td>33.04</td>
                <td>41.35</td>
              </tr>
              <tr>
                <td><a>Phi-3.5</a></td>
                <td>4.2B</td>
                <td>Open</td>
                <td>60.60</td>
                <td>41.82</td>
                <td>45.97</td>
                <td>21.25</td>
                <td>36.89</td>
                <td>30.95</td>
                <td>25.58</td>
                <td>34.66</td>
                <td>39.30</td>
                <td>33.00</td>
                <td>46.03</td>
                <td>49.33</td>
                <td>39.67</td>
                <td>33.47</td>
                <td>39.67</td>
              </tr>
              <tr>
                <td><a>Oryx</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>53.20</td>
                <td>40.43</td>
                <td>48.95</td>
                <td>45.00</td>
                <td>40.68</td>
                <td>56.06</td>
                <td>50.50</td>
                <td>36.71</td>
                <td>48.55</td>
                <td>72.50</td>
                <td>40.01</td>
                <td>48.33</td>
                <td>39.67</td>
                <td>36.98</td>
                <td>49.87</td>
              </tr>
              <tr>
                <td><a>Qwen2-VL</a></td>
                <td>7B</td>
                <td>Open</td>
                <td>76.70</td>
                <td>49.33</td>
                <td>45.12</td>
                <td>37.50</td>
                <td>47.62</td>
                <td>51.24</td>
                <td>22.83</td>
                <td>39.45</td>
                <td>47.23</td>
                <td>57.00</td>
                <td>47.40</td>
                <td>47.74</td>
                <td>35.83</td>
                <td>42.31</td>
                <td>48.60</td>
              </tr>
              <tr>
                <td><a>Qwen2-VL</a></td>
                <td>72B</td>
                <td>Open</td>
                <td>59.80</td>
                <td>51.05</td>
                <td>48.55</td>
                <td>45.50</td>
                <td>50.57</td>
                <td>57.25</td>
                <td>52.25</td>
                <td>45.89</td>
                <td>48.59</td>
                <td>58.25</td>
                <td>50.85</td>
                <td>47.88</td>
                <td>44.83</td>
                <td>46.23</td>
                <td>50.50</td>
              </tr>
              <tr>
                <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              </tr>
              <tr>
                <td><a>DriveLM</a></td>
                <td>7B</td>
                <td>Specialist</td>
                <td>21.20</td>
                <td>42.86</td>
                <td>20.04</td>
                <td>21.25</td>
                <td>37.49</td>
                <td>21.92</td>
                <td>9.00</td>
                <td>36.68</td>
                <td>15.56</td>
                <td>22.25</td>
                <td>42.05</td>
                <td>17.07</td>
                <td>17.50</td>
                <td>39.56</td>
                <td>10.37</td>
              </tr>
              <tr>
                <td><a>Dolphins</a></td>
                <td>7B</td>
                <td>Specialist</td>
                <td>54.30</td>
                <td>30.21</td>
                <td>31.08</td>
                <td>3.00</td>
                <td>30.42</td>
                <td>29.38</td>
                <td>9.42</td>
                <td>26.83</td>
                <td>26.30</td>
                <td>9.25</td>
                <td>29.82</td>
                <td>28.05</td>
                <td>21.50</td>
                <td>28.86</td>
                <td>27.65</td>
              </tr>
            </tbody>
          </table>
          <span>
            <b>Table.</b> <strong>Evaluations of VLMs across different driving tasks</strong> (perception, prediction, planning, and behavior). <span style="color: rgb(0, 176, 80);">Clean</span> represents clean image inputs. <span style="color: rgb(192, 0, 0);">Corr.</span> represents corruption image inputs, averaged across fifteen corruptions. <span style="color: rgb(66, 133, 244);">T.O.</span> represents text-only evaluation. For humans, we only evaluate MCQ questions in perception and behavior tasks. The evaluations are based on GPT scores, where we tailored detailed rubrics for each task and question type.
          </span>
        </div><hr>
  </div>
</div>




<section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/gpt_rouge_bleu.png" loading="lazy" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 40px;">
            <h2 class="title is-3">
              ROUGE, BLEU, or GPT Score?
            </h2>
            <p>
              Evaluation results when using different metrics. 
              The language metrics, such as <b>ROUGE-L</b> and <b>BLEU-4</b>, exhibit high consistency; 
              while the <b>GPT Score</b> metric demonstrates a noticeable gap compared to existing language metrics. 
              We also observe that fine-tuned process benefits DriveLM significantly in regulating its response format, thus leading to misleading high performance under language metrics.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>

  <br/>


  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-right: 40px;">
            <h2 class="title is-3">
              <span class="icon"><i class="fa fa-industry"></i></span>&thinsp; Behavior Distributions of Steering & Speed in DriveLM
            </h2>
            <p>
              We notice that the majority actions of vehicle behaviors are “Going Ahead”, while only a small proportion of actions are “Turn Left” or “Turn Right”.
            </p>
            <p>
              This leads to the data <b>distribution imbalance</b> issue in evaluating different vision-language models.
            </p>
          </div>
        </div>
        <!-- Right Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="static/figures/behavior_distribution.png" loading="lazy" style="max-width: 100%; height: auto;" />
        </div>
      </div><hr>
    </div>
  </section>


  <br/>


  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class=" column is-full-width has-text-centered">
          <h2 class="title is-3">
            <span class="icon"><i class="fa fa-paw"></i></span>&thinsp; GPT4-o Examples
          </h2>
        <img src="static/figures/examples_gpt4o_1.png" loading="lazy"/>
        <div class="content has-text-justified" style="padding-top: 15px">
          <p>
            <b>Figure.</b> Examples of GPT-4o responses to four tasks and the corresponding evaluation results under the <b>Dark</b> condition. 
            We observe that GPT-4o is aware of the low-light environment and can identify the bus and pedestrian from the image, showing certain degrees of resilience.
          </p>

          <br/><br/><br/>

        <div class="pipeline" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
          <img src="static/figures/examples_gpt4o_2.png" loading="lazy"/>

        <div class="content has-text-justified" style="padding-top: 15px">
          <br/>
          <p>
            <b>Figure.</b> Examples of GPT-4o response to four tasks and the corresponding evaluation results under the <b>Motion Blur</b> condition. 
            We observe that GPT-4o are influenced by this type of corruption and tend to predict "driving fast" based on it. 
            The example shows the potential of visual corruption to influence high-level driving decisions.
          </p>
        </div>
        </div>
        <hr>
      </div>
    </div>
    </div>
    </section>



  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class=" column is-full-width has-text-centered">
          <h2 class="title is-3">
            Evaluation Types (Rubric, Question & Context)
          </h2>

        <div class="pipeline" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
          <img src="static/figures/evaluation_types.png" loading="lazy"/>

        <div class="content has-text-justified" style="padding-top: 15px">
          <br/>
          <p>
            <b>Figure.</b> Comparisons among <b>Different Evaluation Types</b> (rubric, question-aware, and context-aware). 
            The GPT scores vary depending on the rubric, question, and physical driving context. With more information added, the results become more distinguishable.
          </p>
        </div>
        </div>
        <hr>
      </div>
    </div>
    </div>
    </section>



    <br/>


  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class=" column is-full-width has-text-centered">
          <h2 class="title is-3">
            Qualitative Comparisons
          </h2>
        <img src="static/figures/examples_benchmark_3.png" loading="lazy"/>
        <div class="content has-text-justified" style="padding-top: 15px">
          <p>
            <b>Figure.</b> Examples of different VLM responses under the <b>Frame Lost</b> condition. 
            We observe that GPT-4o responses with visible objects while LLaVA-NeXT and DriveLM tend to hallucinate objects that cannot be seen from the provided images.
          </p>

          <br/><br/><br/>

        <div class="pipeline" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
          <img src="static/figures/examples_benchmark_4.png" loading="lazy"/>

        <div class="content has-text-justified" style="padding-top: 15px">
          <br/>
          <p>
            <b>Figure.</b> Examples of different VLM responses under the <b>Water Splash</b> condition. 
            We observe that, under severe visual corruptions, VLMs respond with ambiguous and general answers based on their learned knowledge, without referring to the visual information. 
            Most responses include traffic signals and pedestrians, even though they are not visible in the provided images.
          </p>
        </div>
        </div>
        <hr>
      </div>
    </div>
    </div>
    </section>







  <script>
    /**********************************************************
     * Global State
     **********************************************************/
    let selectedCase = 'case1';
    let selectedModel = 'gpt-4o';
    let selectedCorruption = 'clean';
    let selectedPrompt = 'baseline';
  
    let currentCaseData = null;     // Will store Q, A, and image paths
    let currentModelOutput = null;  // Will store the model's answer + all prompts
  
    // For convenience, lists of possible options:
    const cases = ['case1', 'case2'];
    const models = ['gpt-4o', 'qwen-72b', 'drivelm'];
    const corruptions = ['clean', 'text-only', 'snow', 'saturate', 'motion', 'h265'];
    const prompts = ['baseline', 'rubric-aware', 'question-aware', 'context-aware'];
  
    /**********************************************************
     * Utility Functions
     **********************************************************/
    function highlightCoordinates(text, color) {
      if (!text) return '';
      return text
        .replace(/\*\*([^*]+)\*\*/g, `<strong style="color: ${color};">$1</strong>`)
        .replace(/\n/g, '<br>');
    }
  
    // Helper to highlight the currently selected button
    function updateButtonStyles(containerId, selectedValue) {
      const container = document.getElementById(containerId);
      const buttons = container.querySelectorAll('button');
      buttons.forEach(btn => {
        // If button is the selected one
        if (btn.dataset.value === selectedValue) {
          btn.style.backgroundColor = 'rgb(66, 133, 244)';
          btn.style.color = '#fff';
        } else {
          btn.style.backgroundColor = '';
          btn.style.color = '';
        }
      });
    }
  
    // Disable or enable the context-aware prompt button for case2
    function updateContextAwareButtonState() {
      const contextAwareBtn = document.querySelector(
        '#promptButtons button[data-value="context-aware"]'
      );
      if (!contextAwareBtn) return;
  
      if (selectedCase === 'case2') {
        // Disable, gray out
        contextAwareBtn.disabled = true;
        contextAwareBtn.style.backgroundColor = 'gray';
        contextAwareBtn.style.color = '#fff';
      } else {
        // Enable if not case2
        contextAwareBtn.disabled = false;
        // If context-aware is the selected prompt, re-apply highlight
        updateButtonStyles('promptButtons', selectedPrompt);
      }
    }
  
    /**********************************************************
     * Fetching Data
     **********************************************************/
    async function fetchCaseData(caseName) {
      try {
        const response = await fetch(`./static/demos/cases/${caseName}.json`);
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        return await response.json();
      } catch (error) {
        console.error('Error fetching case data:', error);
        throw error;
      }
    }
  
    async function fetchModelOutput(caseName, model, corruption) {
      const modelLower = model.toLowerCase();
      const filePath = `./static/demos/res/${caseName}-${modelLower}-${corruption}.json`;
      try {
        const response = await fetch(filePath);
        if (!response.ok) {
          // If the file is missing or there's an error, throw
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        return await response.json();
      } catch (error) {
        console.error('Error fetching model output:', error);
        throw error;
      }
    }
  
    /**********************************************************
     * Update DOM Functions
     **********************************************************/
    // Update only the question and GT from the case data
    function updateQuestionAndGT() {
      const questionContainer = document.getElementById('questionContainer');
      const gtContainer = document.getElementById('gtContainer');
  
      if (!currentCaseData) {
        questionContainer.innerHTML = '<p style="color: red;">No data.</p>';
        gtContainer.innerHTML = '<p style="color: red;">No data.</p>';
        return;
      }
      questionContainer.innerHTML = `
        <p style="background-color: rgb(238,244,250); color: rgb(51,94,150); margin: 0; padding: 10px;">
          <strong>Question:</strong> 
          ${highlightCoordinates(currentCaseData.Q, 'rgb(51,94,150)')}
        </p>
      `;
      gtContainer.innerHTML = `
        <p style="background-color: rgb(250,224,160); color: rgb(224,146,53); margin: 0; padding: 10px;">
          <strong>GT:</strong> 
          ${highlightCoordinates(currentCaseData.A, 'rgb(224,146,53)')}
        </p>
      `;
    }
  
    // Update only the model answer
    function updateModelAnswer() {
      const answerContainer = document.getElementById('answerContainer');
      if (!currentModelOutput) {
        answerContainer.innerHTML = '<p style="color: red;">No model output.</p>';
        return;
      }
      answerContainer.innerHTML = `
        <p style="background-color: rgb(222,241,211); color: rgb(76,124,49); margin: 0; padding: 10px;">
          <strong>Answer:</strong>
          ${highlightCoordinates(currentModelOutput.A, 'rgb(76,124,49)')}
        </p>
      `;
    }
  
    // Update only the evaluator text (depends on the selected prompt)
    function updateEvaluator() {
      const evaluatorContainer = document.getElementById('evaluatorContainer');
      if (!currentModelOutput || !currentModelOutput[selectedPrompt]) {
        evaluatorContainer.innerHTML = '<p style="color: red;">No evaluator output.</p>';
        return;
      }
      evaluatorContainer.innerHTML = `
        <p style="background-color: rgb(236,208,236); color: rgb(110,39,107); margin: 0; padding: 10px;">
          <strong>Evaluator:</strong> 
          ${highlightCoordinates(currentModelOutput[selectedPrompt], 'rgb(110,39,107)')}
        </p>
      `;
    }
  
    // Update images if needed
    function updateImages() {
      const imageContainer = document.getElementById('imageContainer');
      imageContainer.innerHTML = ''; // Clear old images
  
      if (!currentCaseData) return;
  
      let imgPath = currentCaseData.img;
      if (selectedCorruption === 'text-only') {
        imgPath = currentCaseData['text-only-img'];
      } else {
        // If the JSON uses placeholders, replace them
        if (Array.isArray(imgPath)) {
          imgPath = imgPath.map(path => path.replace('{corruption}', selectedCorruption));
        } else {
          imgPath = imgPath.replace('{corruption}', selectedCorruption);
        }
      }
  
      const images = Array.isArray(imgPath) ? imgPath : [imgPath];
      images.forEach((imgSrc, index) => {
        const imageColumn = document.createElement('div');
        imageColumn.className = images.length === 1 ? 'column is-half' : 'column is-one-third';
        imageColumn.innerHTML = `
          <img src="${imgSrc}" alt="Case Image ${index + 1}" style="width: 100%; max-width: 500px;">
        `;
        imageContainer.appendChild(imageColumn);
      });
    }
  
    /**********************************************************
     * Main Update Logic
     **********************************************************/
    // 1) If case changes, fetch new case data + new model data.
    async function handleCaseChange(newCase) {
      selectedCase = newCase;
  
      // If currently set to context-aware and we switch to case2 => revert to baseline
      if (selectedCase === 'case2' && selectedPrompt === 'context-aware') {
        selectedPrompt = 'baseline';
        updateButtonStyles('promptButtons', selectedPrompt);
      }
  
      // Highlight the new selection
      updateButtonStyles('caseButtons', selectedCase);
  
      // Fetch the new case data
      try {
        currentCaseData = await fetchCaseData(selectedCase);
        updateQuestionAndGT();
        updateImages();
      } catch (err) {
        currentCaseData = null;
        console.error(err);
      }
  
      // Then fetch model output
      try {
        currentModelOutput = await fetchModelOutput(selectedCase, selectedModel, selectedCorruption);
        updateModelAnswer();
        updateEvaluator();
      } catch (err) {
        currentModelOutput = null;
        console.error(err);
      }
  
      // Disable/enable context-aware prompt if it's case2
      updateContextAwareButtonState();
    }
  
    // 2) If model or corruption changes, only fetch the new model output.
    async function handleModelOrCorruptionChange(type, newValue) {
      if (type === 'model') {
        selectedModel = newValue;
        updateButtonStyles('modelButtons', selectedModel);
      } else if (type === 'corruption') {
        selectedCorruption = newValue;
        updateButtonStyles('corruptionButtons', selectedCorruption);
  
        // If corruption changed, we also update images
        if (currentCaseData) {
          updateImages();
        }
      }
  
      // Now fetch new model output (only if we have case data)
      if (currentCaseData) {
        try {
          currentModelOutput = await fetchModelOutput(selectedCase, selectedModel, selectedCorruption);
          updateModelAnswer();
          updateEvaluator();
        } catch (err) {
          currentModelOutput = null;
          console.error(err);
        }
      }
    }
  
    // 3) If prompt changes, only update the Evaluator text.
    function handlePromptChange(newPrompt) {
      // If user is on case2 and tries context-aware => revert to baseline
      if (selectedCase === 'case2' && newPrompt === 'context-aware') {
        selectedPrompt = 'baseline';
      } else {
        selectedPrompt = newPrompt;
      }
  
      updateButtonStyles('promptButtons', selectedPrompt);
      updateEvaluator();
  
      // Also refresh the disabled state in case we tried to pick context-aware on case2
      updateContextAwareButtonState();
    }
  
    /**********************************************************
     * Initialization - Create Buttons and Bind Events
     **********************************************************/
    function createButtons(containerId, values, onClickFn) {
      const container = document.getElementById(containerId);
      container.innerHTML = ''; // Clear any existing content
  
      values.forEach(val => {
        const btn = document.createElement('button');
        btn.className = 'button';
        btn.textContent = val;
        btn.dataset.value = val;
        btn.addEventListener('click', () => onClickFn(val));
        container.appendChild(btn);
      });
    }
  
    // Create all button groups
    createButtons('caseButtons', cases, (val) => handleCaseChange(val));
    createButtons('modelButtons', models, (val) => handleModelOrCorruptionChange('model', val));
    createButtons('corruptionButtons', corruptions, (val) => handleModelOrCorruptionChange('corruption', val));
    createButtons('promptButtons', prompts, (val) => handlePromptChange(val));
  
    // Initial highlight
    updateButtonStyles('caseButtons', selectedCase);
    updateButtonStyles('modelButtons', selectedModel);
    updateButtonStyles('corruptionButtons', selectedCorruption);
    updateButtonStyles('promptButtons', selectedPrompt);
  
    // Load initial data and set button states
    handleCaseChange(selectedCase);
  </script>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xie2025drivebench,
  author  = {Xie, Shaoyuan and Kong, Lingdong and Dong, Yuhao and Sima, Chonghao and Zhang, Wenwei and Chen, Qi Alfred and Liu, Ziwei and Pan, Liang},
  title   = {Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives},
  journal = {arXiv preprint arXiv:2501.04003},
  year    = {2025},
}</code></pre>
  </div>
</section>


<br/><br/>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
              Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
